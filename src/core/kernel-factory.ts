/**
 * ŒûKernel Factory - Easy Setup with Real APIs
 * 
 * Simplifies kernel creation with different LLM providers
 */

import { ŒûKernel, MockLLMPort } from './xi-kernel';
import { OpenAIPort } from './llm-providers/openai-port';
import { AnthropicPort } from './llm-providers/anthropic-port';
import { envConfig } from '../config/environment';

export type ProviderType = 'openai' | 'anthropic' | 'mock';

export interface KernelFactoryOptions {
  provider: ProviderType;
  model?: string;
  temperature?: number;
  maxTokens?: number;
  apiKey?: string;
  enableCostTracking?: boolean;
}

export class KernelFactory {
  /**
   * Create a ŒûKernel with real API integration
   */
  static async create(options: KernelFactoryOptions): Promise<ŒûKernel> {
    const config = envConfig.getConfig();

    switch (options.provider) {
      case 'openai':
        const openaiKey = options.apiKey || config.openai.apiKey || '';
        if (!openaiKey) {
          throw new Error('OpenAI API key is required. Set OPENAI_API_KEY environment variable.');
        }
        const openaiPort = new OpenAIPort({
          apiKey: openaiKey,
          model: options.model || config.openai.model,
          temperature: options.temperature || config.openai.temperature,
          maxTokens: options.maxTokens || config.openai.maxTokens
        });
        return new ŒûKernel(openaiPort);

      case 'anthropic':
        const anthropicKey = options.apiKey || config.anthropic.apiKey || '';
        if (!anthropicKey) {
          throw new Error('Anthropic API key is required. Set ANTHROPIC_API_KEY environment variable.');
        }
        const anthropicPort = new AnthropicPort({
          apiKey: anthropicKey,
          model: options.model || config.anthropic.model,
          temperature: options.temperature || config.anthropic.temperature,
          maxTokens: options.maxTokens || config.anthropic.maxTokens
        });
        return new ŒûKernel(anthropicPort);

      case 'mock':
        return new ŒûKernel(new MockLLMPort());

      default:
        throw new Error(`Unknown provider: ${options.provider}`);
    }
  }

  /**
   * Create kernel with automatic provider detection
   */
  static async createAuto(): Promise<ŒûKernel> {
    const validation = envConfig.validateConfig();
    
    if (!validation.valid) {
      console.warn('No API keys found, using mock provider');
      return this.create({ provider: 'mock' });
    }

    const availableProviders = envConfig.getAvailableProviders();
    
    // Prefer OpenAI, fallback to Anthropic, then mock
    if (availableProviders.includes('openai')) {
      console.log('ü§ñ Using OpenAI provider');
      return this.create({ provider: 'openai' });
    } else if (availableProviders.includes('anthropic')) {
      console.log('ü§ñ Using Anthropic provider');
      return this.create({ provider: 'anthropic' });
    } else {
      console.log('ü§ñ Using mock provider');
      return this.create({ provider: 'mock' });
    }
  }

  /**
   * Quick setup for common scenarios
   */
  static async quickStart(): Promise<{
    kernel: ŒûKernel;
    provider: string;
    ready: boolean;
  }> {
    try {
      const kernel = await this.createAuto();
      const config = envConfig.getConfig();
      const providers = envConfig.getAvailableProviders();
      
      console.log('‚úÖ ŒûKernel initialized successfully');
      console.log(`üì° Provider: ${providers[0] || 'mock'}`);
      console.log(`‚öôÔ∏è  Max recursion: ${config.kernel.maxRecursionDepth}`);
      console.log(`üí∞ Cost tracking: ${config.costs.enableTracking ? 'enabled' : 'disabled'}`);
      
      return {
        kernel,
        provider: providers[0] || 'mock',
        ready: true
      };
      
    } catch (error) {
      console.error('‚ùå Failed to initialize ŒûKernel:', error);
      
      // Fallback to mock
      const kernel = await this.create({ provider: 'mock' });
      return {
        kernel,
        provider: 'mock',
        ready: false
      };
    }
  }
}