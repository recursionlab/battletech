/**
 * Clean OpenRouter Port - No Unicode Issues
 * 
 * Simple OpenRouter integration for XiKernel
 */

import { LLMPort, LLMSpec, LLMResponse, LLMDelta } from '../xi-kernel';

interface OpenRouterMessage {
  role: 'system' | 'user' | 'assistant';
  content: string;
}

interface OpenRouterRequest {
  model: string;
  messages: OpenRouterMessage[];
  temperature?: number;
  max_tokens?: number;
}

interface OpenRouterResponse {
  id: string;
  choices: Array<{
    message: {
      content: string;
      role: string;
    };
    finish_reason: string;
  }>;
  usage: {
    prompt_tokens: number;
    completion_tokens: number;
    total_tokens: number;
  };
  model: string;
}

export class CleanOpenRouterPort implements LLMPort {
  private apiKey: string;
  private model: string;
  private temperature: number;
  private maxTokens: number;

  constructor(config: {
    apiKey: string;
    model?: string;
    temperature?: number;
    maxTokens?: number;
  }) {
    this.apiKey = config.apiKey;
  this.model = config.model || 'openrouter/sonoma-dusk-alpha';
    this.temperature = config.temperature || 0.7;
    this.maxTokens = config.maxTokens || 2000;
  }

  async prompt(symbolId: string, spec: LLMSpec): Promise<LLMResponse> {
    const systemPrompt = `You are an AI operating in XiKernel, a symbolic reasoning system.

Symbol: ${symbolId}
Task: ${spec.task}
Context: ${JSON.stringify(spec.context)}

Respond clearly and concisely. Your output becomes part of a persistent knowledge graph.`;

    const messages: OpenRouterMessage[] = [
      { role: 'system', content: systemPrompt },
      { role: 'user', content: spec.task }
    ];

    const request: OpenRouterRequest = {
      model: this.model,
      messages,
      temperature: this.temperature,
      max_tokens: this.maxTokens
    };

    try {
      const response = await fetch('https://openrouter.ai/api/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${this.apiKey}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify(request)
      });

      if (!response.ok) {
        const errorText = await response.text();
        throw new Error(`OpenRouter API error (${response.status}): ${errorText}`);
      }

  const data = await response.json() as OpenRouterResponse;
      const content = data.choices[0]?.message?.content || '';

      return {
        payload: content,
        justification: `Generated by ${data.model}`,
        confidence: 0.8,
        tokensUsed: data.usage.total_tokens,
        model: data.model,
        cost: this.calculateCost(data.usage),
        timestamp: new Date()
      };

    } catch (error) {
      throw new Error(`OpenRouter API failed: ${error.message}`);
    }
  }

  async critique(symbolId: string, target: Record<string, any>): Promise<LLMDelta[]> {
    const response = await this.prompt(`${symbolId}_critique`, {
      symbolId: `${symbolId}_critique`,
      task: `Analyze this and suggest one specific improvement: ${JSON.stringify(target)}`,
      context: { critiquing: true },
      constraints: { maxTokens: 200 }
    });

    return [{
      operation: 'update',
      target: symbolId,
      changes: { improvement: response.payload.toString().slice(0, 100) },
      reason: 'AI improvement suggestion',
      confidence: 0.7
    }];
  }

  async link(symbolA: string, symbolB: string, relationSpec: string): Promise<{relation: string, confidence: number}[]> {
    return [{
      relation: relationSpec,
      confidence: 0.8
    }];
  }

  async embed(payload: any): Promise<number[]> {
    // Simple deterministic embedding
    const text = JSON.stringify(payload);
    const hash = this.hash(text);
    return Array(384).fill(0).map((_, i) => Math.sin(hash + i) * 0.5);
  }

  private calculateCost(usage: any): number {
    // Rough estimate: $0.002 per 1K tokens
    return (usage.total_tokens / 1000) * 0.002;
  }

  private hash(str: string): number {
    let hash = 0;
    for (let i = 0; i < str.length; i++) {
      hash = ((hash << 5) - hash + str.charCodeAt(i)) & 0xffffffff;
    }
    return Math.abs(hash);
  }
}