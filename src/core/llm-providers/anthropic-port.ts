/**
 * Anthropic Claude LLMPort Implementation
 *
 * Direct Anthropic integration for ΞKernel
 */

import { LLMPort, LLMSpec, LLMResponse, LLMDelta } from '../xi-kernel';

interface AnthropicRequest {
  model: string;
  max_tokens: number;
  messages: Array<{ role: 'user'; content: string }>;
  temperature?: number;
  system?: string;
}

interface AnthropicResponse {
  id: string;
  content: Array<{ type: 'text'; text: string }>;
  model: string;
  usage: { input_tokens: number; output_tokens: number };
  stop_reason?: string;
}

export class AnthropicPort implements LLMPort {
  private apiKey: string;
  private model: string;
  private temperature: number;
  private maxTokens: number;

  constructor(config: {
    apiKey: string;
    model?: string;
    temperature?: number;
    maxTokens?: number;
  }) {
    this.apiKey = config.apiKey;
    this.model = config.model || 'claude-3-sonnet-20240229';
    this.temperature = config.temperature || 0.7;
    this.maxTokens = config.maxTokens || 2000;
  }

  async prompt(symbolId: string, spec: LLMSpec): Promise<LLMResponse> {
    const systemPrompt = `You are Claude operating in ΞKernel.\nSymbol: ${symbolId}\nTask: ${spec.task}\nContext: ${JSON.stringify(spec.context)}\nRespond clearly.`;

    const request: AnthropicRequest = {
      model: this.model,
      max_tokens: spec.constraints.maxTokens || this.maxTokens,
      temperature: spec.constraints.temperature || this.temperature,
      system: systemPrompt,
      messages: [{ role: 'user', content: spec.task }]
    };

    try {
      const response = await fetch('https://api.anthropic.com/v1/messages', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${this.apiKey}`,
          'Content-Type': 'application/json',
          'anthropic-version': '2023-06-01'
        },
        body: JSON.stringify(request)
      });

      if (!response.ok) {
        const errorText = await response.text();
        throw new Error(`Anthropic API error (${response.status}): ${errorText}`);
      }

      const data: AnthropicResponse = await response.json();
      const content = data.content[0]?.text || '';
      const tokensUsed = data.usage.input_tokens + data.usage.output_tokens;

      return {
        payload: content,
        justification: `Generated by ${data.model}`,
        confidence: 0.8,
        tokensUsed,
        model: data.model,
        cost: this.calculateCost(data.usage),
        timestamp: new Date(),
        metadata: { requestId: data.id, symbolId, provider: 'anthropic' }
      };
    } catch (error: any) {
      const errorMessage =
        error && typeof error === 'object' && 'message' in error
          ? error.message
          : String(error);
      throw new Error(`Anthropic API failed: ${errorMessage}`);
    }
  }

  async critique(symbolId: string, target: Record<string, any>): Promise<LLMDelta[]> {
    const response = await this.prompt(`${symbolId}_critique`, {
      symbolId: `${symbolId}_critique`,
      task: `Analyze this and suggest one specific improvement: ${JSON.stringify(target)}`,
      context: { critiquing: true },
      constraints: { maxTokens: 200 }
    });

    return [{
      operation: 'update',
      target: symbolId,
      changes: { improvement: response.payload.toString().slice(0, 100) },
      reason: 'AI improvement suggestion',
      confidence: 0.7
    }];
  }

  async link(symbolA: string, symbolB: string, relationSpec: string): Promise<{relation: string, confidence: number}[]> {
    return [{ relation: relationSpec, confidence: 0.8 }];
  }

  async embed(payload: any): Promise<number[]> {
    const text = typeof payload === 'string' ? payload : JSON.stringify(payload);
    const hash = this.hash(text);
    return Array(384).fill(0).map((_, i) => Math.sin(hash + i) * 0.5);
  }

  private calculateCost(usage: { input_tokens: number; output_tokens: number }): number {
    return ((usage.input_tokens + usage.output_tokens) / 1000) * 0.003;
  }

  private hash(str: string): number {
    let hash = 0;
    for (let i = 0; i < str.length; i++) {
      hash = ((hash << 5) - hash + str.charCodeAt(i)) & 0xffffffff;
    }
    return Math.abs(hash);
  }
}

